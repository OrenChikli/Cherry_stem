{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from work.unet.data_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_path = r'D:\\Clarifruit\\cherry_stem\\data\\unet_data\\train'\n",
    "test_path = r'D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test'\n",
    "test_aug_path = os.path.join(test_path, 'aug')\n",
    "\n",
    "target_size = (256, 256)\n",
    "modes_dict = {'grayscale': 1, 'rgb': 3}\n",
    "color_mode = 'grayscale'\n",
    "\n",
    "x_folder_name = 'image'\n",
    "y_folder_name = 'label'\n",
    "\n",
    "x_prefix = 'image'\n",
    "y_prefix = 'label'\n",
    "\n",
    "weights_file_name = 'unet_cherry_stem.hdfs5'\n",
    "input_size = (*target_size, modes_dict[color_mode])\n",
    "\n",
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                     width_shift_range=0.05,\n",
    "                     height_shift_range=0.05,\n",
    "                     shear_range=0.05,\n",
    "                     zoom_range=0.05,\n",
    "                     horizontal_flip=True,\n",
    "                     fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_gen = clarifruit_train_generator(batch_size=2,\n",
    "                                       train_path=train_path,\n",
    "                                       image_folder=x_folder_name,\n",
    "                                       mask_folder=y_folder_name,\n",
    "                                       aug_dict=data_gen_args,\n",
    "                                       image_color_mode=color_mode,\n",
    "                                       mask_color_mode=color_mode,\n",
    "                                       image_save_prefix=x_prefix,\n",
    "                                       mask_save_prefix=y_prefix,\n",
    "                                       flag_multi_class=False,\n",
    "                                       num_class=2,\n",
    "                                       save_to_dir=None,\n",
    "                                       target_size=target_size,\n",
    "                                       seed=1)\n",
    "\n",
    "test_gen = clarifruit_train_generator(batch_size=2,\n",
    "                                      train_path=test_path,\n",
    "                                      image_folder=x_folder_name,\n",
    "                                      mask_folder=y_folder_name,\n",
    "                                      aug_dict=data_gen_args,\n",
    "                                      image_color_mode=color_mode,\n",
    "                                      mask_color_mode=color_mode,\n",
    "                                      image_save_prefix=x_prefix,\n",
    "                                      mask_save_prefix=y_prefix,\n",
    "                                      flag_multi_class=False,\n",
    "                                      num_class=2,\n",
    "                                      save_to_dir=None,\n",
    "                                      target_size=target_size,\n",
    "                                      seed=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Clarifruit\\cherry_stem\\work\\unet\\model.py:51: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
      "  model = Model(input = inputs, output = conv10)\n"
     ]
    }
   ],
   "source": [
    "model = unet(input_size=input_size)\n",
    "model_checkpoint = ModelCheckpoint(weights_file_name, monitor='loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_gen, steps_per_epoch=100, epochs=3, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57 images belonging to 1 classes.\n",
      "Found 57 images belonging to 1 classes.\n",
      "\r",
      " 1/30 [>.............................] - ETA: 2:14\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2/30 [=>............................] - ETA: 1:06\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3/30 [==>...........................] - ETA: 43s \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4/30 [===>..........................] - ETA: 31s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5/30 [====>.........................] - ETA: 24s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6/30 [=====>........................] - ETA: 19s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7/30 [======>.......................] - ETA: 16s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8/30 [=======>......................] - ETA: 14s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9/30 [========>.....................] - ETA: 12s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10/30 [=========>....................] - ETA: 10s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "11/30 [==========>...................] - ETA: 9s \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "12/30 [===========>..................] - ETA: 8s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "13/30 [============>.................] - ETA: 7s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "14/30 [=============>................] - ETA: 6s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "15/30 [==============>...............] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "16/30 [===============>..............] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "17/30 [================>.............] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "18/30 [=================>............] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "19/30 [==================>...........] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "20/30 [===================>..........] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "21/30 [====================>.........] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "22/30 [=====================>........] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "23/30 [======================>.......] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "24/30 [=======================>......] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "25/30 [========================>.....] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "26/30 [=========================>....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "27/30 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "28/30 [===========================>..] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "29/30 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "30/30 [==============================] - 7s 248ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7101800825636265, 0.7009129928330243]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_gen, steps=30, callbacks=[model_checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'filenames'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-76083f9d5f2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                  seed=1)\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'generator' object has no attribute 'filenames'"
     ]
    }
   ],
   "source": [
    "test = clarifruit_test_generator(batch_size=1,\n",
    "                                 test_path=test_path,\n",
    "                                 folder=x_folder_name,\n",
    "                                 aug_dict=data_gen_args,\n",
    "                                 save_prefix=x_prefix,\n",
    "                                 color_mode=color_mode,\n",
    "                                 save_to_dir=test_aug_path,\n",
    "                                 target_size=target_size,\n",
    "                                 seed=1)\n",
    "\n",
    "for file in test.filenames:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'samples'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c1747bfbec30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mimg_paths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-c1747bfbec30>\u001b[0m in \u001b[0;36mget_names\u001b[1;34m(datagen)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mbatches_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches_per_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mcurrent_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'generator' object has no attribute 'samples'"
     ]
    }
   ],
   "source": [
    "def get_names(datagen):\n",
    "    batches_per_epoch = datagen.samples // datagen.batch_size + (datagen.samples % datagen.batch_size > 0)\n",
    "    for i in range(batches_per_epoch):\n",
    "        batch = next(datagen)\n",
    "        current_index = ((datagen.batch_index-1) * datagen.batch_size)\n",
    "        if current_index < 0:\n",
    "            if datagen.samples % datagen.batch_size > 0:\n",
    "                current_index = max(0,datagen.samples - datagen.samples % datagen.batch_size)\n",
    "            else:\n",
    "                current_index = max(0,datagen.samples - datagen.batch_size)\n",
    "        index_array = datagen.index_array[current_index:current_index + datagen.batch_size].tolist()\n",
    "        img_paths = [datagen.filepaths[idx] for idx in index_array]\n",
    "        yield img_paths\n",
    "    \n",
    "for name in get_names(test):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57 images belonging to 1 classes.\n",
      "\r",
      " 1/30 [>.............................] - ETA: 11s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3/30 [==>...........................] - ETA: 4s \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5/30 [====>.........................] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7/30 [======>.......................] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9/30 [========>.....................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "11/30 [==========>...................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "13/30 [============>.................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "15/30 [==============>...............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "17/30 [================>.............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "19/30 [==================>...........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "21/30 [====================>.........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "23/30 [======================>.......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "25/30 [========================>.....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "27/30 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "29/30 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "30/30 [==============================] - 2s 52ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test\\aug\\0_predict.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test\\aug\\2_predict.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test\\aug\\5_predict.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test\\aug\\6_predict.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test\\aug\\7_predict.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test\\aug\\8_predict.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test\\aug\\9_predict.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test\\aug\\13_predict.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test\\aug\\14_predict.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test\\aug\\15_predict.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test\\aug\\19_predict.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test\\aug\\22_predict.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test\\aug\\23_predict.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test\\aug\\24_predict.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test\\aug\\26_predict.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test\\aug\\27_predict.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test\\aug\\28_predict.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "d:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: D:\\Clarifruit\\cherry_stem\\data\\unet_data\\test\\aug\\29_predict.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "test = clarifruit_test_generator(batch_size=1,\n",
    "                                 test_path=test_path,\n",
    "                                 folder=x_folder_name,\n",
    "                                 aug_dict=data_gen_args,\n",
    "                                 save_prefix=x_prefix,\n",
    "                                 color_mode=color_mode,\n",
    "                                 save_to_dir=test_aug_path,\n",
    "                                 target_size=target_size,\n",
    "                                 seed=1)\n",
    "\n",
    "results = model.predict_generator(generator=test, steps=30, verbose=1)\n",
    "saveResult(test_aug_path, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
