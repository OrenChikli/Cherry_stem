{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from work.unet.clarifruit_unet import unet_model_functions\n",
    "from work.preprocess import data_functions\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau,EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "params_dict = dict(\n",
    "\n",
    "    train_path=r'D:\\Clarifruit\\cherry_stem\\data\\raw_data\\with_maskes',\n",
    "    test_path=r'D:\\Clarifruit\\cherry_stem\\data\\raw_data\\images_orig',\n",
    "    x_folder_name='image',\n",
    "    y_folder_name='label',\n",
    "    dest_path=r'D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training',\n",
    "    weights_file_name='unet_cherry_stem.hdf5',\n",
    "\n",
    "    data_gen_args=dict(rescale=1. / 255,\n",
    "                       rotation_range=180,\n",
    "                       brightness_range=(1., 1.),\n",
    "                       width_shift_range=0.25,\n",
    "                       height_shift_range=0.25,\n",
    "                       shear_range=0.2,\n",
    "                       zoom_range=0.2,\n",
    "                       horizontal_flip=True,\n",
    "                       vertical_flip=True,\n",
    "                       fill_mode='nearest'),\n",
    "\n",
    "    optimizer='Adam',\n",
    "    optimizer_params=dict(lr=1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    "    pretrained_weights=None,\n",
    "\n",
    "    target_size=(256, 256),\n",
    "    color_mode='grayscale',\n",
    "    mask_color_mode='grayscale',\n",
    "    batch_size=10,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=3000,\n",
    "    valdiation_split=0.2,\n",
    "    validation_steps=300)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 152 images belonging to 1 classes.\n",
      "Found 38 images belonging to 1 classes.\n",
      "Found 152 images belonging to 1 classes.\n",
      "Found 38 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=2, min_lr=0.000001,\n",
    "                              cooldown=1, verbose=1)\n",
    "\n",
    "callbacks = [reduce_lr]\n",
    "params_dict['callbacks'] = callbacks\n",
    "\n",
    "model = unet_model_functions.ClarifruitUnet(**params_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 2869s 956ms/step - loss: 0.0387 - acc: 0.9629 - val_loss: 0.0617 - val_acc: 0.9548\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.03878, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-22_00-55-09\\unet_cherry_stem.hdf5\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 2858s 953ms/step - loss: 0.0304 - acc: 0.9627 - val_loss: 0.0558 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00002: loss improved from 0.03878 to 0.03039, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-22_00-55-09\\unet_cherry_stem.hdf5\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 2853s 951ms/step - loss: 0.0293 - acc: 0.9626 - val_loss: 0.0590 - val_acc: 0.9526\n",
      "\n",
      "Epoch 00003: loss improved from 0.03039 to 0.02922, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-22_00-55-09\\unet_cherry_stem.hdf5\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 2848s 949ms/step - loss: 0.0265 - acc: 0.9626 - val_loss: 0.0575 - val_acc: 0.9538\n",
      "\n",
      "Epoch 00004: loss improved from 0.02922 to 0.02648, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-22_00-55-09\\unet_cherry_stem.hdf5\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 2846s 949ms/step - loss: 0.0254 - acc: 0.9627 - val_loss: 0.0632 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00005: loss improved from 0.02648 to 0.02529, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-22_00-55-09\\unet_cherry_stem.hdf5\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 2842s 947ms/step - loss: 0.0245 - acc: 0.9628 - val_loss: 0.0638 - val_acc: 0.9534\n",
      "\n",
      "Epoch 00006: loss improved from 0.02529 to 0.02457, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-22_00-55-09\\unet_cherry_stem.hdf5\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 2841s 947ms/step - loss: 0.0238 - acc: 0.9628 - val_loss: 0.0692 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00007: loss improved from 0.02457 to 0.02376, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-22_00-55-09\\unet_cherry_stem.hdf5\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 2840s 947ms/step - loss: 0.0230 - acc: 0.9629 - val_loss: 0.0690 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00008: loss improved from 0.02376 to 0.02300, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-22_00-55-09\\unet_cherry_stem.hdf5\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 2843s 948ms/step - loss: 0.0226 - acc: 0.9629 - val_loss: 0.0674 - val_acc: 0.9517\n",
      "\n",
      "Epoch 00009: loss improved from 0.02300 to 0.02260, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-22_00-55-09\\unet_cherry_stem.hdf5\n",
      "Epoch 10/10\n",
      " 745/3000 [======>.......................] - ETA: 34:24 - loss: 0.0222 - acc: 0.9632"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-46e4e506d24a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Clarifruit\\cherry_stem\\work\\unet\\clarifruit_unet\\unet_model_functions.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self, params_dict, saveflag)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msaveflag\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_unet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" -> train_model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Clarifruit\\cherry_stem\\work\\unet\\clarifruit_unet\\unet_model_functions.py\u001b[0m in \u001b[0;36mfit_unet\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m             verbose=1)\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" -> fit_unet\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1658\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1449\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1450\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2977\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2937\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\clarifruit\\cherry_stem\\cherry_venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train_model(params_dict,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 152 images belonging to 1 classes.\n",
      "Found 38 images belonging to 1 classes.\n",
      "Found 152 images belonging to 1 classes.\n",
      "Found 38 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "src_path = r'D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-22_00-55-09'\n",
    "params_dict = unet_model_functions.ClarifruitUnet.load_model(src_path)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=2, min_lr=0.000001,\n",
    "                              cooldown=1, verbose=1)\n",
    "\n",
    "early_stoping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "train_params = dict(\n",
    "\n",
    "    data_gen_args=dict(rescale=1. / 255,\n",
    "                       rotation_range=180,\n",
    "                       brightness_range=[0.2, 1.],\n",
    "                       width_shift_range=0.25,\n",
    "                       height_shift_range=0.25,\n",
    "                       shear_range=0.2,\n",
    "                       zoom_range=[0.5,1.0],\n",
    "                       horizontal_flip=True,\n",
    "                       vertical_flip=True,\n",
    "                       fill_mode='nearest'),\n",
    "\n",
    "    callbacks = [reduce_lr,early_stoping],\n",
    "\n",
    "    batch_size=10,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=3000,\n",
    "    valdiation_split=0.2,\n",
    "    validation_steps=3000)\n",
    "\n",
    "params_dict.update(train_params)\n",
    "\n",
    "model = unet_model_functions.ClarifruitUnet(**params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 3707s 1s/step - loss: 0.0231 - acc: 0.9630 - val_loss: 0.0440 - val_acc: 0.9586\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04400, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-22_23-55-20\\unet_cherry_stem.hdf5\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 3697s 1s/step - loss: 0.0225 - acc: 0.9629 - val_loss: 0.0499 - val_acc: 0.9586\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04400\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 3702s 1s/step - loss: 0.0222 - acc: 0.9630 - val_loss: 0.0515 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04400\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 3706s 1s/step - loss: 0.0220 - acc: 0.9629 - val_loss: 0.0496 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04400\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.train_model(params_dict,saveflag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.save_weights(r\"D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-22_23-55-20\\model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prediction(threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
