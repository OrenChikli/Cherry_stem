{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "BASE_PATH = os.path.abspath('../..')\n",
    "sys.path.append(BASE_PATH)\n",
    "import os\n",
    "import logging\n",
    "from work.auxiliary.logger_settings import configure_logger\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from work.unet import unet_model_functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_PATH = os.path.join(BASE_PATH,'logs')\n",
    "DATA_PATH = os.path.join(BASE_PATH,'data') # create a data folder at the save root folder with the \"work\" folder\n",
    "\n",
    "log_path = data_functions.create_path(LOG_PATH, 'unet_logs')\n",
    "\n",
    "configure_logger(name=\"cherry_stem\",\n",
    "                 console_level='INFO',\n",
    "                 file_level='INFO',\n",
    "                 out_path=log_path)\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_path = os.path.join(BASE_PATH,r'data\\raw_data\\with_maskes') #path where the \"label\" and \"image\" folder resides\n",
    "dest_path =  os.path.join(BASE_PATH,r'data\\unet_data\\training') # the path to save the current session results\n",
    "test_path = os.path.join(BASE_PATH,r'data\\raw_data\\images_orig') # path containig images to segment\n",
    "\n",
    "pretrained_weights = os.path.join(DATA_PATH, r'unet_data\\training\\2019-09-30_07-19-46\\unet_cherry_stem.hdf5')\n",
    "\n",
    "src_path = os.path.join(BASE_PATH,r'data\\unet_data\\training\\2019-10-15_16-21-49') # optional path to load a pretrained model\n",
    "                                                                                  # to continue trainig\n",
    "steps=None # number of steps to select where to continue the trainig from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = dict(\n",
    "\n",
    "    train_path=train_path,\n",
    "    save_path=dest_path,\n",
    "    x_folder_name='image', # the name of the 'image' folder within the train path (contains the X data or images)\n",
    "    y_folder_name='label', # the name of the 'label' folder within the train path (contains the Y data or labels)\n",
    "\n",
    "    save_name='cherry', # name used as basename for all output which is save (the base file name)\n",
    "\n",
    "    pretrained_weights=pretrained_weights, # path to pretrained wights which can be loaded for this training session\n",
    "    checkpoint=None, #optional, path to pretrained folder of pretrained model which can be loaded for this training session\n",
    "    data_gen_args=dict(rotation_range=180,\n",
    "                       brightness_range=[0.2, 1.],\n",
    "                       shear_range=5,\n",
    "                       zoom_range=0.5,\n",
    "                       horizontal_flip=True,\n",
    "                       vertical_flip=True,\n",
    "                       fill_mode='nearest'),# augmentaion arguments for the imageDataGen module in keras\n",
    "    seed=78,# Random seed used in the generation of the train images\n",
    "\n",
    "    optimizer='Adam',# name of the optimizer to use, can be any of the optimizer in: https://keras.io/optimizers/\n",
    "    optimizer_params=dict(lr=1e-5,\n",
    "                          amsgrad=False),\n",
    "\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[],# list of metrics which will be monitored during trainig\n",
    "\n",
    "    target_size=(256, 256), # the source images are resized for computetional efficiency to this target size\n",
    "    color_mode='grayscale', # where to train of rgb images or convert to grayscale\n",
    "\n",
    "    batch_size=10,  # my GPU cant handel any more\n",
    "\n",
    "    epochs=15,\n",
    "    steps_per_epoch=100,\n",
    "    validation_split=0.2,\n",
    "    validation_steps=200,\n",
    "\n",
    "     tensorboard_update_freq=250, #update frequency for the metrics and iamges displayed in tensorboard\n",
    "    weights_update_freq='epoch', #frequency to save the model to chekpoint, if 'epoch' than after each trainig epoch\n",
    "    save_weights_only=True, # whether to save just the model weights or the model itself\n",
    "    ontop_display_threshold=0.4, # creates binary masks for model predicionts with pixel values greater than this, which are\n",
    "    #shown in tensorboard\n",
    "    callbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2,\n",
    "                                 verbose=1, mode='auto', min_delta=0.0001,\n",
    "                                 cooldown=0, min_lr=1e-6)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load exsisting model\n",
    "\n",
    "update_dict = dict(tensorboard_update_freq=5000,\n",
    "                   weights_update_freq=20000,\n",
    "                   optimizer_params=dict(lr=1e-6)) # optional dictionay to update the loaded model parameters \n",
    "\n",
    "\n",
    "model = unet_model_functions.ClarifruitUnet.load_model(src_path,steps)\n",
    "model.update_model(**update_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 152 images belonging to 1 classes.\n",
      "Found 38 images belonging to 1 classes.\n",
      "Found 152 images belonging to 1 classes.\n",
      "Found 38 images belonging to 1 classes.\n",
      "Found 152 images belonging to 1 classes.\n",
      "Found 38 images belonging to 1 classes.\n",
      "Found 152 images belonging to 1 classes.\n",
      "Found 38 images belonging to 1 classes.\n",
      "tensorboard --logdir=D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-10-16_01-02-23\\keras_logs\n"
     ]
    }
   ],
   "source": [
    "keras_logs_path=model.set_model_for_train()\n",
    "print(f\"tensorboard --logdir={keras_logs_path}\") #commad for activating tensorboard for this session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.0433 - val_loss: 0.0648\n",
      "\n",
      "Epoch 00001: saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-10-16_01-02-23\\cherry_weights.train_sess_01.steps_476.loss_0.0441.hdf5\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 62s 1s/step - loss: 0.0322 - val_loss: 0.0548\n",
      "\n",
      "Epoch 00002: saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-10-16_01-02-23\\cherry_weights.train_sess_01.steps_952.loss_0.0325.hdf5\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 62s 1s/step - loss: 0.0314 - val_loss: 0.0529\n",
      "\n",
      "Epoch 00003: saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-10-16_01-02-23\\cherry_weights.train_sess_01.steps_1428.loss_0.0312.hdf5\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 62s 1s/step - loss: 0.0302 - val_loss: 0.0515\n",
      "\n",
      "Epoch 00004: saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-10-16_01-02-23\\cherry_weights.train_sess_01.steps_1904.loss_0.0306.hdf5\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 63s 1s/step - loss: 0.0301 - val_loss: 0.0506\n",
      "\n",
      "Epoch 00005: saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-10-16_01-02-23\\cherry_weights.train_sess_01.steps_2380.loss_0.0299.hdf5\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 62s 1s/step - loss: 0.0285 - val_loss: 0.0482\n",
      "\n",
      "Epoch 00006: saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-10-16_01-02-23\\cherry_weights.train_sess_01.steps_2856.loss_0.0286.hdf5\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 62s 1s/step - loss: 0.0277 - val_loss: 0.0483\n",
      "\n",
      "Epoch 00007: saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-10-16_01-02-23\\cherry_weights.train_sess_01.steps_3332.loss_0.0278.hdf5\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 61s 1s/step - loss: 0.0277 - val_loss: 0.0481\n",
      "\n",
      "Epoch 00008: saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-10-16_01-02-23\\cherry_weights.train_sess_01.steps_3800.loss_0.0283.hdf5\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 62s 1s/step - loss: 0.0268 - val_loss: 0.0483\n",
      "\n",
      "Epoch 00009: saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-10-16_01-02-23\\cherry_weights.train_sess_01.steps_4276.loss_0.0271.hdf5\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 62s 1s/step - loss: 0.0275 - val_loss: 0.0459\n",
      "\n",
      "Epoch 00010: saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-10-16_01-02-23\\cherry_weights.train_sess_01.steps_4752.loss_0.0277.hdf5\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 63s 1s/step - loss: 0.0275 - val_loss: 0.0492\n",
      "\n",
      "Epoch 00011: saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-10-16_01-02-23\\cherry_weights.train_sess_01.steps_5228.loss_0.0272.hdf5\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 62s 1s/step - loss: 0.0268 - val_loss: 0.0464\n",
      "\n",
      "Epoch 00012: saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-10-16_01-02-23\\cherry_weights.train_sess_01.steps_5704.loss_0.0272.hdf5\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 63s 1s/step - loss: 0.0276 - val_loss: 0.0472\n",
      "\n",
      "Epoch 00013: saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-10-16_01-02-23\\cherry_weights.train_sess_01.steps_6180.loss_0.0277.hdf5\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 63s 1s/step - loss: 0.0257 - val_loss: 0.0458\n",
      "\n",
      "Epoch 00014: saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-10-16_01-02-23\\cherry_weights.train_sess_01.steps_6656.loss_0.0261.hdf5\n",
      "Epoch 15/30\n",
      "17/50 [=========>....................] - ETA: 30s - loss: 0.0280"
     ]
    }
   ],
   "source": [
    "model.fit_unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-13 09:48:57,533-6d  INFO     work.unet.unet_model_functions: prediction on files from D:\\Clarifruit\\cherry_stem\\data\\raw_data\\images_orig\n",
      "2019-10-13 09:48:57,535-6d  INFO     work.unet.unet_model_functions: saving predictions to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-10-13_03-58-48\\raw_pred\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:\\\\Clarifruit\\\\cherry_stem\\\\data\\\\unet_data\\\\training\\\\2019-10-13_03-58-48\\\\raw_pred'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prediction(test_path,dest_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
