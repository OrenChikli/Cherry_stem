{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from work.unet.clarifruit_unet import  keras_functions\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "#import tensorflow.python.util.deprecation as deprecation\n",
    "#deprecation._PRINT_DEPRECATION_WARNINGS = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "init_params = dict(\n",
    "    train_path=r'D:\\Clarifruit\\cherry_stem\\data\\raw_data\\with_maskes',\n",
    "    test_path=r'D:\\Clarifruit\\cherry_stem\\data\\raw_data\\images_orig',\n",
    "    x_folder_name='image',\n",
    "    y_folder_name='label',\n",
    "    dest_path=r'D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training',\n",
    "    weights_file_name='unet_cherry_stem.hdf5')\n",
    "\n",
    "data_gen_args = dict(rescale=1. / 255,\n",
    "                     rotation_range=0.5,\n",
    "                     width_shift_range=0.25,\n",
    "                     height_shift_range=0.25,\n",
    "                     shear_range=0.25,\n",
    "                     zoom_range=0.2,\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=True,\n",
    "                     fill_mode='nearest')\n",
    "\n",
    "unet_params = dict(optimizer=Adam(lr=1e-4),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'],\n",
    "                   pretrained_weights =r'D:\\Clarifruit\\cherry_stem\\data\\unet_data\\model data\\2019-09-15_19-05-19\\unet_cherry_stem.hdf5'\n",
    "                  )\n",
    "\n",
    "fit_params = dict(target_size=(256, 256),\n",
    "                  color_mode='rgb',\n",
    "                  batch_size=10,\n",
    "                  epochs=8,\n",
    "                  steps_per_epoch=3000,\n",
    "                  validation_steps=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=2, min_lr=0.000001,\n",
    "                              cooldown=1, verbose=1)\n",
    "callbacks = [reduce_lr]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 152 images belonging to 1 classes.\n",
      "Found 38 images belonging to 1 classes.\n",
      "Found 152 images belonging to 1 classes.\n",
      "Found 38 images belonging to 1 classes.\n",
      "Epoch 1/8\n",
      "3000/3000 [==============================] - 2792s 931ms/step - loss: 0.2286 - acc: 0.9408 - val_loss: 0.2695 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.22861, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-18_00-41-49\\unet_cherry_stem.hdf5\n",
      "Epoch 2/8\n",
      "3000/3000 [==============================] - 2778s 926ms/step - loss: 0.2283 - acc: 0.9410 - val_loss: 0.2699 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00002: loss improved from 0.22861 to 0.22815, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-18_00-41-49\\unet_cherry_stem.hdf5\n",
      "Epoch 3/8\n",
      "3000/3000 [==============================] - 2781s 927ms/step - loss: 0.2290 - acc: 0.9408 - val_loss: 0.2721 - val_acc: 0.9325\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.22815\n",
      "Epoch 4/8\n",
      "3000/3000 [==============================] - 2782s 927ms/step - loss: 0.2292 - acc: 0.9409 - val_loss: 0.2709 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.22815\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 5/8\n",
      "3000/3000 [==============================] - 2782s 927ms/step - loss: 0.2297 - acc: 0.9408 - val_loss: 0.2698 - val_acc: 0.9331\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.22815\n",
      "Epoch 6/8\n",
      "3000/3000 [==============================] - 2785s 928ms/step - loss: 0.2284 - acc: 0.9410 - val_loss: 0.2690 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.22815\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 7/8\n",
      "3000/3000 [==============================] - 2809s 936ms/step - loss: 0.2286 - acc: 0.9409 - val_loss: 0.2699 - val_acc: 0.9331\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.22815\n",
      "Epoch 8/8\n",
      "3000/3000 [==============================] - 2795s 932ms/step - loss: 0.2283 - acc: 0.9411 - val_loss: 0.2699 - val_acc: 0.9331\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.22815\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1e-06.\n"
     ]
    }
   ],
   "source": [
    "model = keras_functions.train_model(init_params,\n",
    "                                    data_gen_args,\n",
    "                                    unet_params,\n",
    "                                    fit_params,\n",
    "                                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.1) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:3363: error: (-215:Assertion failed) !dsize.empty() in function 'cv::hal::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b34ed7fb5779>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Clarifruit\\cherry_stem\\work\\unet\\clarifruit_unet\\keras_functions.py\u001b[0m in \u001b[0;36mprediction\u001b[1;34m(self, threshold)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m             \u001b[0msave_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_entry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mCOLOR_TO_OPENCV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morig_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mpred_image_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.1) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:3363: error: (-215:Assertion failed) !dsize.empty() in function 'cv::hal::resize'\n"
     ]
    }
   ],
   "source": [
    "model.prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
