{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from work.unet.clarifruit_unet import  keras_functions\n",
    "from work.preprocess import data_functions\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "path_params = dict(\n",
    "    train_path=r'D:\\Clarifruit\\cherry_stem\\data\\raw_data\\with_maskes',\n",
    "    test_path=r'D:\\Clarifruit\\cherry_stem\\data\\raw_data\\images_orig',\n",
    "    x_folder_name='image',\n",
    "    y_folder_name='label',\n",
    "    dest_path=r'D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training',\n",
    "    weights_file_name='unet_cherry_stem.hdf5')\n",
    "\n",
    "data_gen_args = dict(rescale=1. / 255,\n",
    "                     rotation_range=0.5,\n",
    "                     width_shift_range=0.25,\n",
    "                     height_shift_range=0.25,\n",
    "                     shear_range=0.05,\n",
    "                     zoom_range=0.2,\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=True,\n",
    "                     fill_mode='nearest')\n",
    "\n",
    "optimizer_params =dict(lr=1e-4)\n",
    "\n",
    "extra_params = dict(data_gen_args=data_gen_args,\n",
    "                    optimizer_params=optimizer_params)\n",
    "\n",
    "unet_params = dict(optimizer='Adam',\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'],\n",
    "                   pretrained_weights=None)\n",
    "#r'D:\\Clarifruit\\cherry_stem\\data\\unet_data\\model data\\2019-09-15_15-33-49\\unet_cherry_stem.hdf5')\n",
    "\n",
    "fit_params = dict(target_size=(256, 256),\n",
    "                  color_mode='grayscale',\n",
    "                  batch_size=10,\n",
    "                  epochs=10,\n",
    "                  steps_per_epoch=3000,\n",
    "                  valdiation_split=0.2,\n",
    "                  validation_steps=300)\n",
    "\n",
    "init_dict = data_functions.join_dicts(path_params,unet_params,fit_params,extra_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=2, min_lr=0.000001,\n",
    "                              cooldown=1, verbose=1)\n",
    "\n",
    "callbacks = [reduce_lr]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model = keras_functions.ClarifruitUnet(**init_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 152 images belonging to 1 classes.\n",
      "Found 38 images belonging to 1 classes.\n",
      "Found 152 images belonging to 1 classes.\n",
      "Found 38 images belonging to 1 classes.\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 2848s 949ms/step - loss: 0.0377 - acc: 0.9409 - val_loss: 0.0570 - val_acc: 0.9325\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.03774, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-18_22-19-04\\unet_cherry_stem.hdf5\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 2842s 947ms/step - loss: 0.0278 - acc: 0.9410 - val_loss: 0.0623 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00002: loss improved from 0.03774 to 0.02776, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-18_22-19-04\\unet_cherry_stem.hdf5\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 2837s 946ms/step - loss: 0.0247 - acc: 0.9409 - val_loss: 0.0648 - val_acc: 0.9292\n",
      "\n",
      "Epoch 00003: loss improved from 0.02776 to 0.02464, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-18_22-19-04\\unet_cherry_stem.hdf5\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 2834s 945ms/step - loss: 0.0229 - acc: 0.9410 - val_loss: 0.0708 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00004: loss improved from 0.02464 to 0.02287, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-18_22-19-04\\unet_cherry_stem.hdf5\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 2835s 945ms/step - loss: 0.0218 - acc: 0.9410 - val_loss: 0.0683 - val_acc: 0.9295\n",
      "\n",
      "Epoch 00005: loss improved from 0.02287 to 0.02172, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-18_22-19-04\\unet_cherry_stem.hdf5\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 2833s 944ms/step - loss: 0.0208 - acc: 0.9413 - val_loss: 0.0689 - val_acc: 0.9288\n",
      "\n",
      "Epoch 00006: loss improved from 0.02172 to 0.02077, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-18_22-19-04\\unet_cherry_stem.hdf5\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 2835s 945ms/step - loss: 0.0201 - acc: 0.9412 - val_loss: 0.0712 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00007: loss improved from 0.02077 to 0.02009, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-18_22-19-04\\unet_cherry_stem.hdf5\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 2837s 946ms/step - loss: 0.0195 - acc: 0.9413 - val_loss: 0.0720 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00008: loss improved from 0.02009 to 0.01952, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-18_22-19-04\\unet_cherry_stem.hdf5\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 2832s 944ms/step - loss: 0.0194 - acc: 0.9413 - val_loss: 0.0739 - val_acc: 0.9297\n",
      "\n",
      "Epoch 00009: loss improved from 0.01952 to 0.01939, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-18_22-19-04\\unet_cherry_stem.hdf5\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 2831s 944ms/step - loss: 0.0187 - acc: 0.9415 - val_loss: 0.0737 - val_acc: 0.9290\n",
      "\n",
      "Epoch 00010: loss improved from 0.01939 to 0.01876, saving model to D:\\Clarifruit\\cherry_stem\\data\\unet_data\\training\\2019-09-18_22-19-04\\unet_cherry_stem.hdf5\n"
     ]
    }
   ],
   "source": [
    "model.train_model(path_params, data_gen_args, unet_params,fit_params,optimizer_params,callbacks=callbacks,saveflag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "function takes exactly 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b34ed7fb5779>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Clarifruit\\cherry_stem\\work\\unet\\clarifruit_unet\\keras_functions.py\u001b[0m in \u001b[0;36mprediction\u001b[1;34m(self, threshold)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m             \u001b[0mpred_image_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m             \u001b[0mpred_image_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_image_raw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[0mpred_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: function takes exactly 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "model.prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
